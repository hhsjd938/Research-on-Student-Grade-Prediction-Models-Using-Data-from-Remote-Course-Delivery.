# -*- coding: utf-8 -*-
"""Logistic regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v_lDZk_jQQG7czLLSt73U9nLUhPXU5v_
"""

import time
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix
from imblearn.combine import SMOTEENN
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties
import numpy as np

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"使用設備: {device}")

start_time = time.time()
print("程式開始運行...")

import os
font_path = '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc'
print("字體是否存在：", os.path.exists(font_path))

# 上傳 CSV 檔案
from google.colab import files
uploaded = files.upload()
data = pd.read_csv(list(uploaded.keys())[0], encoding='latin1')

# 替換原始欄位名稱
data.columns = [
    "學年", "學期", "cou_code", "造訪次數", "停留時長(秒)", "影音查看次數", "影音查看率(%)",
    "影音觀看時長(秒)", "參考檔案查看及下載次數", "參考檔案下載率(%)", "線上連結查看次數", "線上連結查看率(%)",
    "作業繳交次數", "已交作業數", "應交作業數", "作業繳交率(%)", "線上測驗繳交次數", "已交測試數",
    "應交測試數", "線上測驗繳交率(%)", "發表文章數", "發表文章數回覆數", "討論參與率(%)", "出席", "缺席",
    "請假", "出席率(%)", "課程完成度(%)", "點名成績", "課程成績", "及格與否", "分數等級"
]

# 指定目標欄位
target_column = '及格與否'

X = data.drop(columns=[
    target_column, "課程成績", "分數等級", "cou_code",
])
y = data[target_column]

# 類別獨熱編碼
X = pd.get_dummies(X, drop_first=True)

# 處理缺失值 (此處以平均值/眾數填補)
X.fillna(X.mean(), inplace=True)
y.fillna(y.mode()[0], inplace=True)

# 資料集切分
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# 使用 SMOTEENN 進行重採樣
smote_enn = SMOTEENN(random_state=42)
X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train, y_train)

# 標準化
scaler = StandardScaler()
X_train_resampled = scaler.fit_transform(X_train_resampled)
X_test = scaler.transform(X_test)

# 轉為 Tensor
X_train_tensor = torch.tensor(X_train_resampled, dtype=torch.float32).to(device)
y_train_tensor = torch.tensor(y_train_resampled.values, dtype=torch.float32).to(device)
X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)
y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)

"""邏輯回歸"""

class LogisticRegressionModel(nn.Module):
    def __init__(self, input_dim):
        super().__init__()
        self.linear = nn.Linear(input_dim, 1)
    def forward(self, x):
        return torch.sigmoid(self.linear(x))

# 初始化 Logistic Regression
input_dim = X_train_tensor.shape[1]
model = LogisticRegressionModel(input_dim).to(device)

# 損失函數 & 優化器
criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=0.0001)

# 訓練參數
epochs = 600
batch_size = 128

# 訓練迴圈
for epoch in range(epochs):
    model.train()
    permutation = torch.randperm(X_train_tensor.size(0))
    epoch_loss = 0.0

    for i in range(0, X_train_tensor.size(0), batch_size):
        indices = permutation[i:i+batch_size]
        batch_X, batch_y = X_train_tensor[indices], y_train_tensor[indices]
        outputs = model(batch_X).squeeze()
        loss = criterion(outputs, batch_y)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item()

    if (epoch+1) % 10 == 0 or (epoch == 0):
        print(f"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}")

# 評估模型
eval_start_time = time.time()
model.eval()
with torch.no_grad():
    y_pred_prob = model(X_test_tensor).squeeze().cpu().numpy()

"""最佳閥值"""

best_threshold = 0.5
min_combined_metric = float('inf')
import numpy as np
from sklearn.metrics import confusion_matrix

for threshold in np.arange(0.0, 1.1, 0.1):
    y_pred = (y_pred_prob > threshold).astype(int)
    cm = confusion_matrix(y_test, y_pred)
    TN, FP, FN, TP = cm.ravel()
    error_rate = (FP + FN) / (TP + TN + FP + FN)
    fnr = FN / (TP + FN) if (TP + FN) > 0 else 0
    combined_metric = error_rate + fnr
    if combined_metric < min_combined_metric:
        min_combined_metric = combined_metric
        best_threshold = threshold

eval_end_time = time.time()
print(f"\n評估時間: {eval_end_time - eval_start_time:.2f} 秒")
print(f"最佳閾值: {best_threshold:.2f}")

"""混淆矩陣跟性能"""

y_pred_final = (y_pred_prob > best_threshold).astype(int)
cm = confusion_matrix(y_test, y_pred_final)
TN, FP, FN, TP = cm.ravel()

accuracy = (TP + TN) / (TP + TN + FP + FN)
error_rate = 1 - accuracy
sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0
specificity = TN / (TN + FP) if (TN + FP) > 0 else 0
false_positive_rate = FP / (FP + TN) if (FP + TN) > 0 else 0
false_negative_rate = FN / (TP + FN) if (TP + FN) > 0 else 0
precision_positive = TP / (TP + FP) if (TP + FP) > 0 else 0
precision_negative = TN / (TN + FN) if (TN + FN) > 0 else 0
F1_positive = (2 * precision_positive * sensitivity) / (precision_positive + sensitivity) if (precision_positive + sensitivity) > 0 else 0
F1_negative = (2 * precision_negative * specificity) / (precision_negative + specificity) if (precision_negative + specificity) > 0 else 0

print("\n[混淆矩陣]")
print(cm)
print("\n[性能指標]")
print(f"Accuracy(準確度): {accuracy:.4f}")
print(f"Error Rate(錯誤率): {error_rate:.4f}")
print(f"Sensitivity(靈敏度): {sensitivity:.4f}")
print(f"Specificity(特異度): {specificity:.4f}")
print(f"False Positive Rate(假陽率): {false_positive_rate:.4f}")
print(f"False Negative Rate(假陰率): {false_negative_rate:.4f}")
print(f"Precision(P)(陽精確度): {precision_positive:.4f}")
print(f"Precision(N)(陰精確度): {precision_negative:.4f}")
print(f"F1 Score(P)(陽): {F1_positive:.4f}")
print(f"F1 Score(N)(陰): {F1_negative:.4f}")

"""特徵權重"""

font_path = '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc'
font_prop = FontProperties(fname=font_path)

with torch.no_grad():
    # 在 Logistic Regression 中，只有一層 linear.weight
    input_weights = model.linear.weight.data.cpu().numpy().flatten()
feature_importance = np.abs(input_weights)
feature_names = X.columns

imp_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})
imp_df = imp_df.sort_values(by='Importance', ascending=False)

# 只顯示前 20 個特徵
top_features = imp_df.head(20)
plt.figure(figsize=(10, 8))
plt.barh(top_features['Feature'], top_features['Importance'], color='skyblue')
plt.gca().invert_yaxis()
plt.xlabel('權重絕對值(重要性)', fontsize=12, fontproperties=font_prop)
plt.ylabel('特徵名稱', fontsize=12, fontproperties=font_prop)
plt.title('Logistic Regression 特徵重要性(僅作參考)', fontproperties=font_prop, fontsize=16)
plt.tight_layout()
plt.show()

print("\n程式結束，總耗時: {:.2f} 秒".format(time.time() - start_time))